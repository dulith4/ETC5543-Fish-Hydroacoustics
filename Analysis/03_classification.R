# ==============================================================================
# 03_classification.R
# PURPOSE
#   Run H2O AutoML on fish acoustic data summarized by quintiles (5 rows per fish).
#   Splits fish IDs into 60/20/20 (train/valid/test), trains models, evaluates,
#   and saves leaderboard, predictions, and best model artifacts.
#
# RUN THIS AT LEAST ONCE:
#   Must be run once to generate outputs in `outputs/tables/` and `outputs/models/`.
#   After that, results can be viewed repeatedly with:
#     source("Analysis/view_results_quintiles.R")
#
# INPUTS
#   - outputs/tables/fish_freq_quintiles_long.rds
#     (auto-generated by Analysis/02b_fish_quantiles.R if missing)
#
# OUTPUTS (timestamped)
#   - outputs/tables/automl_leaderboard_YYYYMMDD_HHMMSS.rds / .csv
#   - outputs/tables/predictions_valid_YYYYMMDD_HHMMSS.rds / .csv
#   - outputs/tables/predictions_test_YYYYMMDD_HHMMSS.rds / .csv
#   - outputs/models/<AutoML best model + MOJO binaries>
#
# NOTES
#   - Target = species (SMB vs LT).
#   - Features = all frequency columns F45–F170.
#   - Runtime budget currently set to 300 seconds.
#   - Models are saved in `outputs/models/` (for reproducibility).
#     Most collaborators only need the results in `outputs/tables/`
#     and can explore them with the viewer script.
# ==============================================================================

# ---- 0. Setup ----
rm(list = ls())

seed <- 20250904

suppressPackageStartupMessages({
  library(tidyverse)
  library(h2o)
  library(glue)
  library(readr)
  library(forcats)
  library(here)
})

dir.create("outputs", showWarnings = FALSE)
dir.create("outputs/tables", showWarnings = FALSE, recursive = TRUE)
dir.create("outputs/models", showWarnings = FALSE, recursive = TRUE)

utils_path <- "Analysis/utils_data.R"
if (file.exists(utils_path)) source(utils_path)

# Ensure required quintile file exists (build if missing)
quintile_rds <- here("outputs", "tables", "fish_freq_quintiles_long.rds")
builder_r    <- here("Analysis", "02b_fish_quantiles.R")

if (!file.exists(quintile_rds)) {
  message("Quintile file not found — running: ", builder_r)
  source(builder_r, local = TRUE)
  if (!file.exists(quintile_rds)) stop("Expected file not created: ", quintile_rds)
}

# ---- 1. Load transformed features ----
path_features <- quintile_rds  # outputs/tables/fish_freq_quantiles_long.rds
dat <- readRDS(path_features) |>
  mutate(
    species  = fct_drop(as.factor(species)),
    fishNum  = as.character(fishNum),
    quantile = as.factor(quantile)
  )

# Identify feature columns (all frequency columns)
feature_cols <- names(dat)[grepl("^F\\d", names(dat))]
stopifnot(length(feature_cols) > 0)

# ---- 2. Fish-level, species-stratified split (60/20/20) ----
set.seed(seed)
fish_ids <- dat |> distinct(fishNum, species)

split_species_ids <- function(df_ids, p_train = 0.6, p_valid = 0.2, seed = 1) {
  vec_ids <- df_ids$fishNum
  n <- length(vec_ids)
  set.seed(seed)
  idx <- sample(n)
  
  n_train <- floor(p_train * n)
  n_valid <- floor(p_valid * n)
  n_test  <- n - n_train - n_valid
  
  if (n_train == 0 || n_valid == 0 || n_test == 0) {
    # fallback to avoid empty groups
    n_train <- max(1, floor(0.70 * n))
    n_valid <- max(1, floor(0.15 * n))
    n_test  <- max(1, n - n_train - n_valid)
  }
  
  train_ids <- vec_ids[idx[seq_len(n_train)]]
  valid_ids <- vec_ids[idx[seq(n_train + 1, length.out = n_valid)]]
  test_ids  <- vec_ids[idx[seq(n_train + n_valid + 1, length.out = n_test)]]
  
  tibble(
    fishNum = c(train_ids, valid_ids, test_ids),
    split   = c(rep("train", length(train_ids)),
                rep("valid", length(valid_ids)),
                rep("test",  length(test_ids)))
  )
}

split_map <- fish_ids |>
  group_split(species) |>
  purrr::map_dfr(~ split_species_ids(.x, p_train = 0.6, p_valid = 0.2, seed = seed))

dat_s <- dat |> left_join(split_map, by = "fishNum")
stopifnot(!any(is.na(dat_s$split)))

# ---- 3. Prep H2O frames ----
h2o.init()

cols_keep <- c("species", "fishNum", "quantile", feature_cols)

train_df <- dat_s |> filter(split == "train") |> select(all_of(cols_keep))
valid_df <- dat_s |> filter(split == "valid") |> select(all_of(cols_keep))
test_df  <- dat_s |> filter(split == "test")  |> select(all_of(cols_keep))

train_h2o <- as.h2o(train_df)
valid_h2o <- as.h2o(valid_df)
test_h2o  <- as.h2o(test_df)

y <- "species"
x <- feature_cols

train_h2o[[y]] <- as.factor(train_h2o[[y]])
valid_h2o[[y]] <- as.factor(valid_h2o[[y]])
test_h2o[[y]]  <- as.factor(test_h2o[[y]])

# ---- 4. AutoML (short budget, simple first pass) ----
runtime_secs <- 300

aml <- h2o.automl(
  x = x, y = y,
  training_frame    = train_h2o,
  validation_frame  = valid_h2o,
  leaderboard_frame = test_h2o,
  max_runtime_secs  = runtime_secs,
  nfolds            = 0,
  sort_metric       = "AUC",
  seed              = seed
)

leader <- aml@leader
timestamp <- format(Sys.time(), "%Y%m%d_%H%M%S")

# Save leaderboard (no printing)
lb <- as.data.frame(aml@leaderboard)
write_csv(lb, glue("outputs/tables/automl_leaderboard_{timestamp}.csv"))
saveRDS(lb,  glue("outputs/tables/automl_leaderboard_{timestamp}.rds"))

# ---- 5. Key metrics only (VALID & TEST) ----
perf_valid <- h2o.performance(leader, newdata = valid_h2o)
perf_test  <- h2o.performance(leader, newdata = test_h2o)

# Find numeric thresholds that maximise F1, then use them
thr_v <- h2o.find_threshold_by_max_metric(perf_valid, "f1")
thr_t <- h2o.find_threshold_by_max_metric(perf_test,  "f1")

# numeric accuracy at the chosen thresholds (coerce from list -> numeric)
acc_valid <- as.numeric(unlist(h2o.accuracy(perf_valid, thresholds = thr_v)))
acc_test  <- as.numeric(unlist(h2o.accuracy(perf_test,  thresholds = thr_t)))

cat("\n==== VALIDATION ====\n")
cat("AUC: ", h2o.auc(perf_valid), "\n", sep = "")
cat("Threshold (max F1): ", thr_v, "\n", sep = "")
cat("Accuracy (thr=max_f1): ", sprintf("%.4f", acc_valid), "\n", sep = "")
cm_valid <- as.data.frame(h2o.confusionMatrix(perf_valid, thresholds = thr_v))
print(cm_valid)

cat("\n==== TEST ====\n")
cat("AUC: ", h2o.auc(perf_test), "\n", sep = "")
cat("Threshold (max F1): ", thr_t, "\n", sep = "")
cat("Accuracy (thr=max_f1): ", sprintf("%.4f", acc_test), "\n", sep = "")
cm_test <- as.data.frame(h2o.confusionMatrix(perf_test, thresholds = thr_t))
print(cm_test)

# ---- 6. Predictions (saved, not printed) ----
pred_valid <- as.data.frame(h2o.predict(leader, valid_h2o)) |>
  bind_cols(as.data.frame(valid_h2o)[, c("fishNum", "species", "quantile")])

pred_test <- as.data.frame(h2o.predict(leader, test_h2o)) |>
  bind_cols(as.data.frame(test_h2o)[, c("fishNum", "species", "quantile")])

write_csv(pred_valid, glue("outputs/tables/predictions_valid_{timestamp}.csv"))
saveRDS(pred_valid, glue("outputs/tables/predictions_valid_{timestamp}.rds"))
write_csv(pred_test,  glue("outputs/tables/predictions_test_{timestamp}.csv"))
saveRDS(pred_test,  glue("outputs/tables/predictions_test_{timestamp}.rds"))

# ---- 7. Save best model (path only, no print spam) ----
saved_path <- h2o.saveModel(leader, path = "outputs/models", force = TRUE)
invisible(h2o.download_mojo(leader, path = "outputs/models", get_genmodel_jar = TRUE))

cat(glue("\nSaved model: {saved_path}\n"))

# ---- 8. Save artifacts via utility (with leaderboard) ----
source("Analysis/utils_models.R")
lb   <- h2o.get_leaderboard(aml, extra_columns = "ALL")
best <- best_from_aml(aml)
save_h2o_artifacts(best, tag = "fish_ping", leaderboard = lb, train = train_hex, save_binary = TRUE)
